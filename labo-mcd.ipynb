{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install featurewiz==0.2.0","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:57:06.981610Z","iopub.execute_input":"2023-05-02T21:57:06.981890Z","iopub.status.idle":"2023-05-02T21:57:07.008036Z","shell.execute_reply.started":"2023-05-02T21:57:06.981863Z","shell.execute_reply":"2023-05-02T21:57:07.007150Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\narchivos = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        archivos.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-02T21:56:16.266468Z","iopub.execute_input":"2023-05-02T21:56:16.267398Z","iopub.status.idle":"2023-05-02T21:56:16.305062Z","shell.execute_reply.started":"2023-05-02T21:56:16.267346Z","shell.execute_reply":"2023-05-02T21:56:16.303961Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/dset-pequenio/DiccionarioDatos_2023.ods\n/kaggle/input/lab1-complete-parquet/downsampled_df.csv\n/kaggle/input/lab1-complete-parquet/downsampled_df.parquet\n/kaggle/input/dset-peq/dataset_pequeno.csv\n/kaggle/input/error-falopa/error_falopa.csv\n/kaggle/input/laboratorio-de-imp-i-2023-virtual/kaggle_competencia_muestra.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nimport seaborn as sns\nimport category_encoders as ce\nimport os\n\n\nfrom sklearn.tree import plot_tree\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import f1_score, make_scorer, classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion    \nfrom sklearn.utils.validation import check_is_fitted\n\nfrom featurewiz import featurewiz\nfrom scipy import sparse\n\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 200)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:56:17.276344Z","iopub.execute_input":"2023-05-02T21:56:17.277088Z","iopub.status.idle":"2023-05-02T21:56:20.907236Z","shell.execute_reply.started":"2023-05-02T21:56:17.277045Z","shell.execute_reply":"2023-05-02T21:56:20.905384Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"Imported 0.2.00 version. Select nrows to a small number when running on huge datasets.\noutput = featurewiz(dataname, target, corr_limit=0.90, verbose=2, sep=',', \n\t\theader=0, test_data='',feature_engg='', category_encoders='',\n\t\tdask_xgboost_flag=False, nrows=None, skip_sulov=False)\nCreate new features via 'feature_engg' flag : ['interactions','groupby','target']\n\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_file = '/kaggle/input/lab1-complete-parquet/downsampled_df.csv'\n\ndataset = pd.read_csv(dataset_file)\ndataset.drop(columns='Unnamed: 0', inplace=True)\nprint(dataset_file)\ndataset['clase_ternaria'].replace({'BAJA+2': 1, 'BAJA+1':1, 'CONTINUA':0}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:56:20.909502Z","iopub.execute_input":"2023-05-02T21:56:20.909872Z","iopub.status.idle":"2023-05-02T21:56:22.883772Z","shell.execute_reply.started":"2023-05-02T21:56:20.909832Z","shell.execute_reply":"2023-05-02T21:56:22.882589Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/lab1-complete-parquet/downsampled_df.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"def find_cols_with_high_nan(df, threshold=0.80, drop=True): \n    nan_pct = df.isna().sum() / len(df)    \n    # Select columns with NaN percentage greater than the threshold\n    high_nan_cols = nan_pct[nan_pct > threshold].index.tolist()\n    if drop:\n        print(f'dropeando {high_nan_cols} porque tienen mas de {threshold} Nan...')\n        return df.drop(columns=high_nan_cols)\n    return high_nan_cols\n\ndef join_visa_master(df):\n    print('juntando columnas con prefijo Visa_ y Master_')\n    visa_columns = df.filter(like='Visa_').columns.to_list()\n    master_columns = df.filter(like='Master_').columns.to_list()\n    \n    for col_visa, col_master in zip(visa_columns, master_columns):\n        new_column_name = 'sum_' + col_visa.split('_', 1)[1]\n        \n        # Replace NaN values with 0 temporarily for the sum\n        visa_values = df[col_visa].fillna(0)\n        master_values = df[col_master].fillna(0)\n        \n        # Sum the non-NaN values and store the result in the new column\n        df[new_column_name] = visa_values + master_values\n        df[new_column_name] = df[new_column_name].replace(0, np.nan)\n    \n    return df.drop(columns=visa_columns+master_columns)\n\n\ndef join_cols(df, string):\n    joined_cols = df.filter(like=string)\n    print(f'sumando las columnas: {joined_cols.columns.to_list()}...')\n    \n    # Replace NaN values with 0 temporarily for the sum\n    joined_cols_filled = joined_cols.fillna(0)\n    \n    # Calculate the sum\n    sum_values = joined_cols_filled.sum(axis=1)\n    \n    # Replace 0 values with NaN after the summation, but keep the original 0 values when both columns have 0 values in the same row\n    df[string] = sum_values.where((joined_cols_filled != 0).any(axis=1), joined_cols_filled.sum(axis=1))\n    \n    return df.drop(columns=joined_cols.columns)\n\ndef find_good_ratios(data):\n    '''crea ratios de todas las features float y se queda con los que featurewiz le da importancia, devuelve una lista de buenos candidatos para ratio'''\n    def _create_ratios(dataframe, variable,target):\n        float_cols = dataframe.select_dtypes(include='float64').columns.tolist()    \n        new_dataframe = pd.DataFrame()    \n        for col in float_cols:\n            if col != variable:\n                new_col_name = f'{variable}_to_{col}'\n                new_dataframe[new_col_name] = dataframe[variable] / dataframe[col]\n                new_dataframe.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n        new_dataframe[target] = dataframe[target]\n        return new_dataframe    \n    \n    the_best = []\n    for i in data.select_dtypes(include='float64').columns.tolist():\n        temp_df = _create_ratios(data, i,'clase_ternaria')\n        try:\n            best_ratios = featurewiz(temp_df, 'clase_ternaria',verbose=0)\n            the_best.append(best_ratios[0])\n        except:\n            the_best.append(f'error with {i}')\n    return the_best\n\ndef create_ratios_from_best(df, lista_best):\n    '''crea las features a partir de una lista de listas que tiene los mejores ratios'''\n    data = df.copy()    \n    for ratios in lista_best:\n        if \"error\" in ratios:\n            print(f\"Skipping invalid ratio: {ratios}\")\n            continue\n        else:\n            for j in ratios:\n                variables = j.split('_to_')\n                data[j] = data[variables[0]] / data[variables[1]]           \n    return data\n\ndef preprocessing_dataset(dataset, palabras_agrupar):\n    print(dataset.shape)\n    dataset = find_cols_with_high_nan(dataset)\n    print(dataset.shape)\n    dataset = join_visa_master(dataset)\n    print(dataset.shape)\n\n    for i in palabras_agrupar:    \n        dataset = join_cols(dataset, i)\n        print(dataset.shape)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:56:22.885603Z","iopub.execute_input":"2023-05-02T21:56:22.886358Z","iopub.status.idle":"2023-05-02T21:56:22.903491Z","shell.execute_reply.started":"2023-05-02T21:56:22.886316Z","shell.execute_reply":"2023-05-02T21:56:22.902373Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"palabras_agrupar =['prestamo','seguro','servicios', 'comisiones','cheques','ahorro','inversion','_consumo','descuentos','tarjeta','consumo','margen','debit','forex', 'transfer','autoservicio','cajas','atm','mobile']","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:56:22.907090Z","iopub.execute_input":"2023-05-02T21:56:22.907365Z","iopub.status.idle":"2023-05-02T21:56:22.917247Z","shell.execute_reply.started":"2023-05-02T21:56:22.907339Z","shell.execute_reply":"2023-05-02T21:56:22.916269Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset = preprocessing_dataset(dataset,palabras_agrupar)\nlist_of_best_ratios = find_good_ratios(dataset)\ndataset = create_ratios_from_best(dataset, list_of_best_ratios)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T21:56:22.919142Z","iopub.execute_input":"2023-05-02T21:56:22.919635Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"(86870, 155)\ndropeando ['Master_Finiciomora', 'Visa_Finiciomora'] porque tienen mas de 0.8 Nan...\n(86870, 153)\njuntando columnas con prefijo Visa_ y Master_\n(86870, 132)\nsumando las columnas: ['cprestamos_personales', 'mprestamos_personales', 'cprestamos_prendarios', 'mprestamos_prendarios', 'cprestamos_hipotecarios', 'mprestamos_hipotecarios']...\n(86870, 127)\nsumando las columnas: ['cseguro_vida', 'cseguro_auto', 'cseguro_vivienda', 'cseguro_accidentes_personales']...\n(86870, 124)\nsumando las columnas: ['cpagodeservicios', 'mpagodeservicios']...\n(86870, 123)\nsumando las columnas: ['mcomisiones', 'ccomisiones_mantenimiento', 'mcomisiones_mantenimiento', 'ccomisiones_otras', 'mcomisiones_otras']...\n(86870, 119)\nsumando las columnas: ['ccheques_depositados', 'mcheques_depositados', 'ccheques_emitidos', 'mcheques_emitidos', 'ccheques_depositados_rechazados', 'mcheques_depositados_rechazados', 'ccheques_emitidos_rechazados', 'mcheques_emitidos_rechazados']...\n(86870, 112)\nsumando las columnas: ['ccaja_ahorro', 'mcaja_ahorro', 'mcaja_ahorro_adicional', 'mcaja_ahorro_dolares']...\n(86870, 109)\nsumando las columnas: ['cinversion1', 'minversion1_pesos', 'minversion1_dolares', 'cinversion2', 'minversion2']...\n(86870, 105)\nsumando las columnas: ['mtarjeta_visa_consumo', 'mtarjeta_master_consumo']...\n(86870, 104)\nsumando las columnas: ['ccajeros_propios_descuentos', 'mcajeros_propios_descuentos', 'ctarjeta_visa_descuentos', 'mtarjeta_visa_descuentos', 'ctarjeta_master_descuentos', 'mtarjeta_master_descuentos']...\n(86870, 99)\nsumando las columnas: ['ctarjeta_debito', 'ctarjeta_debito_transacciones', 'ctarjeta_visa', 'ctarjeta_visa_transacciones', 'ctarjeta_master', 'ctarjeta_master_transacciones', 'ctarjeta_visa_debitos_automaticos', 'mttarjeta_visa_debitos_automaticos', 'ctarjeta_master_debitos_automaticos', 'mttarjeta_master_debitos_automaticos']...\n(86870, 90)\nsumando las columnas: ['sum_mconsumospesos', 'sum_mconsumosdolares', 'sum_mconsumototal', 'sum_cconsumos', '_consumo']...\n(86870, 86)\nsumando las columnas: ['mactivos_margen', 'mpasivos_margen']...\n(86870, 85)\nsumando las columnas: ['ccuenta_debitos_automaticos', 'mcuenta_debitos_automaticos']...\n(86870, 84)\nsumando las columnas: ['cforex', 'cforex_buy', 'mforex_buy', 'cforex_sell', 'mforex_sell']...\n(86870, 80)\nsumando las columnas: ['ctransferencias_recibidas', 'mtransferencias_recibidas', 'ctransferencias_emitidas', 'mtransferencias_emitidas']...\n(86870, 77)\nsumando las columnas: ['mautoservicio', 'cextraccion_autoservicio', 'mextraccion_autoservicio']...\n(86870, 75)\nsumando las columnas: ['ccajas_transacciones', 'ccajas_consultas', 'ccajas_depositos', 'ccajas_extracciones', 'ccajas_otras']...\n(86870, 71)\nsumando las columnas: ['catm_trx', 'matm', 'catm_trx_other', 'matm_other']...\n(86870, 68)\nsumando las columnas: ['tmobile_app', 'cmobile_app_trx']...\n(86870, 67)\n############################################################################################\n############       F A S T   F E A T U R E  E N G G    A N D    S E L E C T I O N ! ########\n# Be judicious with featurewiz. Don't use it to create too many un-interpretable features! #\n############################################################################################\ncorrelation limit = 0.9\nSkipping feature engineering since no feature_engg input...\nSkipping category encoding since no category encoders specified in input...\n#### Single_Label Binary_Classification problem ####\n    Loaded train data. Shape = (86870, 43)\n#### Single_Label Binary_Classification problem ####\nNo test data filename given...\nClassifying features using a random sample of 10000 rows from dataset...\n#### Single_Label Binary_Classification problem ####\n    loading a random sample of 10000 rows into pandas for EDA\n#######################################################################################\n######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n#######################################################################################\n        15 variable(s) to be removed since ID or low-information variables\n    \tvariables removed = ['mrentabilidad_to_mcuenta_corriente_adicional', 'mrentabilidad_to_mplazo_fijo_dolares', 'mrentabilidad_to_mplazo_fijo_pesos', 'mrentabilidad_to_mpayroll2', 'mrentabilidad_to_sum_delinquency', 'mrentabilidad_to_sum_status', 'mrentabilidad_to_sum_madelantopesos', 'mrentabilidad_to_sum_madelantodolares', 'mrentabilidad_to_sum_mpagosdolares', 'mrentabilidad_to_sum_cadelantosefectivo', 'mrentabilidad_to_servicios', 'mrentabilidad_to_cheques', 'mrentabilidad_to_inversion', 'mrentabilidad_to_descuentos', 'mrentabilidad_to_forex']\ntrain data shape before dropping 15 columns = (86870, 43)\n\ttrain data shape after dropping columns = (86870, 28)\n#######################################################################################\n#####  Searching for Uncorrelated List Of Variables (SULOV) in 27 features ############\n#######################################################################################\n    there are no null values in dataset...\n    Removing (2) highly correlated variables:\n    ['mrentabilidad_to_sum_mlimitecompra', 'mrentabilidad_to_sum_msaldototal']\n    Following (25) vars selected: ['mrentabilidad_to_ahorro', 'mrentabilidad_to_atm', 'mrentabilidad_to_autoservicio', 'mrentabilidad_to_comisiones', 'mrentabilidad_to_consumo', 'mrentabilidad_to_debit', 'mrentabilidad_to_margen', 'mrentabilidad_to_mcuenta_corriente', 'mrentabilidad_to_mcuentas_saldo', 'mrentabilidad_to_mobile', 'mrentabilidad_to_mpagomiscuentas', 'mrentabilidad_to_mpayroll', 'mrentabilidad_to_mrentabilidad_annual', 'mrentabilidad_to_prestamo', 'mrentabilidad_to_sum_Fvencimiento', 'mrentabilidad_to_sum_fechaalta', 'mrentabilidad_to_sum_fultimo_cierre', 'mrentabilidad_to_sum_mpagado', 'mrentabilidad_to_sum_mpagominimo', 'mrentabilidad_to_sum_mpagospesos', 'mrentabilidad_to_sum_msaldodolares', 'mrentabilidad_to_tarjeta', 'mrentabilidad_to_transfer', 'mrentabilidad_to_sum_msaldopesos', 'mrentabilidad_to_sum_mfinanciacion_limite']\nCompleted SULOV. 25 features selected\nTime taken for SULOV method = 2 seconds\nFinally 25 vars selected after SULOV\nConverting all features to numeric before sending to XGBoost...\n#######################################################################################\n#####    R E C U R S I V E   X G B O O S T : F E A T U R E   S E L E C T I O N  #######\n#######################################################################################\nCurrent number of predictors before recursive XGBoost = 25 \nNumber of booster rounds = 100\n            selecting 12 features in this iteration\n            selecting 10 features in this iteration\n            selecting 7 features in this iteration\n            selecting 5 features in this iteration\n    Completed XGBoost feature selection in 0 seconds\n#######################################################################################\n#####          F E A T U R E   S E L E C T I O N   C O M P L E T E D            #######\n#######################################################################################\nSelected 14 important features:\n['mrentabilidad_to_mpayroll', 'mrentabilidad_to_consumo', 'mrentabilidad_to_autoservicio', 'mrentabilidad_to_mpagomiscuentas', 'mrentabilidad_to_ahorro', 'mrentabilidad_to_prestamo', 'mrentabilidad_to_mcuenta_corriente', 'mrentabilidad_to_sum_mpagospesos', 'mrentabilidad_to_debit', 'mrentabilidad_to_sum_mpagominimo', 'mrentabilidad_to_sum_mfinanciacion_limite', 'mrentabilidad_to_sum_msaldodolares', 'mrentabilidad_to_sum_msaldopesos', 'mrentabilidad_to_transfer']\nTotal Time taken for featurewiz selection = 5 seconds\nOutput contains a list of 14 important features and a train dataframe\n############################################################################################\n############       F A S T   F E A T U R E  E N G G    A N D    S E L E C T I O N ! ########\n# Be judicious with featurewiz. Don't use it to create too many un-interpretable features! #\n############################################################################################\ncorrelation limit = 0.9\nSkipping feature engineering since no feature_engg input...\nSkipping category encoding since no category encoders specified in input...\n#### Single_Label Binary_Classification problem ####\n    Loaded train data. Shape = (86870, 43)\n#### Single_Label Binary_Classification problem ####\nNo test data filename given...\nClassifying features using a random sample of 10000 rows from dataset...\n#### Single_Label Binary_Classification problem ####\n    loading a random sample of 10000 rows into pandas for EDA\n#######################################################################################\n######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n#######################################################################################\n        15 variable(s) to be removed since ID or low-information variables\n    \tvariables removed = ['mrentabilidad_annual_to_mcuenta_corriente_adicional', 'mrentabilidad_annual_to_mplazo_fijo_dolares', 'mrentabilidad_annual_to_mplazo_fijo_pesos', 'mrentabilidad_annual_to_mpayroll2', 'mrentabilidad_annual_to_sum_delinquency', 'mrentabilidad_annual_to_sum_status', 'mrentabilidad_annual_to_sum_madelantopesos', 'mrentabilidad_annual_to_sum_madelantodolares', 'mrentabilidad_annual_to_sum_mpagosdolares', 'mrentabilidad_annual_to_sum_cadelantosefectivo', 'mrentabilidad_annual_to_servicios', 'mrentabilidad_annual_to_cheques', 'mrentabilidad_annual_to_inversion', 'mrentabilidad_annual_to_descuentos', 'mrentabilidad_annual_to_forex']\ntrain data shape before dropping 15 columns = (86870, 43)\n\ttrain data shape after dropping columns = (86870, 28)\n#######################################################################################\n#####  Searching for Uncorrelated List Of Variables (SULOV) in 27 features ############\n#######################################################################################\n    there are no null values in dataset...\n    Removing (3) highly correlated variables:\n    ['mrentabilidad_annual_to_mrentabilidad', 'mrentabilidad_annual_to_sum_mlimitecompra', 'mrentabilidad_annual_to_sum_msaldopesos']\n    Following (24) vars selected: ['mrentabilidad_annual_to_ahorro', 'mrentabilidad_annual_to_atm', 'mrentabilidad_annual_to_autoservicio', 'mrentabilidad_annual_to_comisiones', 'mrentabilidad_annual_to_consumo', 'mrentabilidad_annual_to_debit', 'mrentabilidad_annual_to_mcuenta_corriente', 'mrentabilidad_annual_to_mcuentas_saldo', 'mrentabilidad_annual_to_mobile', 'mrentabilidad_annual_to_mpagomiscuentas', 'mrentabilidad_annual_to_mpayroll', 'mrentabilidad_annual_to_prestamo', 'mrentabilidad_annual_to_sum_Fvencimiento', 'mrentabilidad_annual_to_sum_fechaalta', 'mrentabilidad_annual_to_sum_fultimo_cierre', 'mrentabilidad_annual_to_sum_mpagado', 'mrentabilidad_annual_to_sum_mpagominimo', 'mrentabilidad_annual_to_sum_mpagospesos', 'mrentabilidad_annual_to_sum_msaldodolares', 'mrentabilidad_annual_to_tarjeta', 'mrentabilidad_annual_to_transfer', 'mrentabilidad_annual_to_sum_msaldototal', 'mrentabilidad_annual_to_sum_mfinanciacion_limite', 'mrentabilidad_annual_to_margen']\nCompleted SULOV. 24 features selected\nTime taken for SULOV method = 2 seconds\nFinally 24 vars selected after SULOV\nConverting all features to numeric before sending to XGBoost...\n#######################################################################################\n#####    R E C U R S I V E   X G B O O S T : F E A T U R E   S E L E C T I O N  #######\n#######################################################################################\nCurrent number of predictors before recursive XGBoost = 24 \nNumber of booster rounds = 100\n            selecting 12 features in this iteration\n            selecting 9 features in this iteration\n            selecting 7 features in this iteration\n            selecting 4 features in this iteration\n    Completed XGBoost feature selection in 0 seconds\n#######################################################################################\n#####          F E A T U R E   S E L E C T I O N   C O M P L E T E D            #######\n#######################################################################################\nSelected 16 important features:\n['mrentabilidad_annual_to_mpayroll', 'mrentabilidad_annual_to_consumo', 'mrentabilidad_annual_to_autoservicio', 'mrentabilidad_annual_to_mpagomiscuentas', 'mrentabilidad_annual_to_prestamo', 'mrentabilidad_annual_to_ahorro', 'mrentabilidad_annual_to_sum_mpagospesos', 'mrentabilidad_annual_to_mcuentas_saldo', 'mrentabilidad_annual_to_mcuenta_corriente', 'mrentabilidad_annual_to_debit', 'mrentabilidad_annual_to_sum_Fvencimiento', 'mrentabilidad_annual_to_sum_mpagominimo', 'mrentabilidad_annual_to_sum_msaldototal', 'mrentabilidad_annual_to_sum_mfinanciacion_limite', 'mrentabilidad_annual_to_transfer', 'mrentabilidad_annual_to_margen']\nTotal Time taken for featurewiz selection = 4 seconds\nOutput contains a list of 16 important features and a train dataframe\n############################################################################################\n############       F A S T   F E A T U R E  E N G G    A N D    S E L E C T I O N ! ########\n# Be judicious with featurewiz. Don't use it to create too many un-interpretable features! #\n############################################################################################\ncorrelation limit = 0.9\nSkipping feature engineering since no feature_engg input...\nSkipping category encoding since no category encoders specified in input...\n#### Single_Label Binary_Classification problem ####\n    Loaded train data. Shape = (86870, 43)\n#### Single_Label Binary_Classification problem ####\nNo test data filename given...\nClassifying features using a random sample of 10000 rows from dataset...\n#### Single_Label Binary_Classification problem ####\n    loading a random sample of 10000 rows into pandas for EDA\n#######################################################################################\n######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n#######################################################################################\n        15 variable(s) to be removed since ID or low-information variables\n    \tvariables removed = ['mcuenta_corriente_adicional_to_mplazo_fijo_dolares', 'mcuenta_corriente_adicional_to_mplazo_fijo_pesos', 'mcuenta_corriente_adicional_to_mpayroll2', 'mcuenta_corriente_adicional_to_mpagomiscuentas', 'mcuenta_corriente_adicional_to_sum_delinquency', 'mcuenta_corriente_adicional_to_sum_status', 'mcuenta_corriente_adicional_to_sum_madelantopesos', 'mcuenta_corriente_adicional_to_sum_madelantodolares', 'mcuenta_corriente_adicional_to_sum_mpagosdolares', 'mcuenta_corriente_adicional_to_sum_cadelantosefectivo', 'mcuenta_corriente_adicional_to_servicios', 'mcuenta_corriente_adicional_to_cheques', 'mcuenta_corriente_adicional_to_inversion', 'mcuenta_corriente_adicional_to_descuentos', 'mcuenta_corriente_adicional_to_forex']\ntrain data shape before dropping 15 columns = (86870, 43)\n\ttrain data shape after dropping columns = (86870, 28)\n#######################################################################################\n#####  Searching for Uncorrelated List Of Variables (SULOV) in 27 features ############\n#######################################################################################\n    there are no null values in dataset...\n","output_type":"stream"}]},{"cell_type":"code","source":"cols_keep_as_is = ['active_quarter','cliente_vip','internet','tcuentas','cdescubierto_preacordado','ccaja_seguridad','tcallcenter','thomebanking','cplazo_fijo','cajas','mobile','ccuenta_corriente','cpayroll2_trx','ctrx_quarter','cpayroll_trx']\ncols_to_binarize = ['cliente_edad','cliente_antiguedad','cproductos','cpagomiscuentas','ccallcenter_transacciones','chomebanking_transacciones','seguro']\ncols_to_normalize = [col for col in dataset.select_dtypes('float').columns if col not in cols_keep_as_is + cols_to_binarize]\n\n#len(cols_keep_as_is + cols_to_binarize+cols_to_normalize) == len(set(cols_keep_as_is + cols_to_binarize+cols_to_normalize))\nset(dataset.columns) - set(cols_keep_as_is + cols_to_binarize+cols_to_normalize)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pipeline preprocessing","metadata":{}},{"cell_type":"code","source":"class ColumnSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.columns = columns\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.columns]\n\n\nclass StandardScalerTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, columns=None):\n        self.columns = columns\n        self.scaler = StandardScaler()\n        \n    def fit(self, X, y=None):\n        cols_to_scale = self.columns or X.select_dtypes(include='number').columns\n        self.scaler.fit(X[cols_to_scale])\n        return self\n        \n    def transform(self, X):\n        cols_to_scale = self.columns or X.select_dtypes(include='number').columns\n        X_transformed = pd.DataFrame(self.scaler.transform(X[cols_to_scale]), columns=cols_to_scale, index=X.index)\n        return pd.concat([X.drop(columns=cols_to_scale), X_transformed], axis=1)\n    \n    \nclass PandasFeatureUnion(BaseEstimator, TransformerMixin):\n    def __init__(self, transformers):\n        self.transformers = transformers\n\n    def fit(self, X, y=None):\n        for _, transformer in self.transformers:\n            transformer.fit(X, y)\n        return self\n\n    def transform(self, X, y=None):\n        transformed_dfs = []\n        for _, transformer in self.transformers:\n            transformed_dfs.append(transformer.transform(X))        \n        \n        concatenated_df = pd.concat(transformed_dfs, axis=1)\n        return concatenated_df\n    \n\nclass BinTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, n_bins, columns=None):\n        self.n_bins = n_bins\n        self.columns = columns\n        \n    def fit(self, X, y=None):\n        self.quantiles_ = {}\n        self.outliers_ = {}\n        cols_to_transform = self.columns or X.select_dtypes(include=np.number).columns\n        for col in cols_to_transform:          \n            q1, q3 = np.percentile(X[col], [25, 75])\n            iqr = q3 - q1\n            lower_bound = q1 - 1.5 * iqr\n            upper_bound = q3 + 1.5 * iqr\n            mask = (X[col] < lower_bound) | (X[col] > upper_bound)\n            self.outliers_[col] = mask\n            col_no_outliers = X.loc[~mask, col]\n            self.quantiles_[col] = pd.qcut(col_no_outliers, self.n_bins, labels=False, duplicates='drop')\n        return self\n\n    def transform(self, X):\n        check_is_fitted(self)\n        X_trans = X.copy()\n        cols_to_transform = self.columns or X_trans.select_dtypes(include=np.number).columns\n        for col in cols_to_transform:         \n            X_trans[col] = pd.cut(X_trans[col], bins=self.n_bins, labels=False, duplicates='drop')\n            X_trans.loc[self.outliers_[col].reindex(X.index, fill_value=False).values, col] = 'outlier'\n            if col in self.quantiles_:\n                X_trans.loc[~self.outliers_[col].reindex(X.index, fill_value=False), col] = 'bin_' + self.quantiles_[col].apply(lambda x: str(x)).astype(str)      \n    \n        return X_trans[cols_to_transform]\n    \n    \nclass OneHotEncoderTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, categorical_cols=None):\n        self.categorical_cols = categorical_cols\n    \n    def fit(self, X, y=None):\n        if self.categorical_cols is None:\n            self.categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n        \n        self.categories_ = [X[col].astype('category').cat.categories.tolist() + ['dummy'] for col in self.categorical_cols]\n        self.encoder = OneHotEncoder(categories=self.categories_, handle_unknown='ignore')\n        self.encoder.fit(X[self.categorical_cols])\n        return self\n    \n    def transform(self, X, y=None):\n        X_transformed = self.encoder.transform(X[self.categorical_cols])\n        feature_names = self.encoder.get_feature_names_out(self.categorical_cols)\n        X_transformed_df = pd.DataFrame.sparse.from_spmatrix(X_transformed, columns=feature_names)\n        X_transformed_df.index = X.index\n        return pd.concat([X.drop(columns=self.categorical_cols), X_transformed_df], axis=1)\n\n\nclass TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n    def __init__(self, cols=None, drop_invariant=False, return_df=True):\n        self.cols = cols\n        self.drop_invariant = drop_invariant\n        self.return_df = return_df\n        self.encoder = ce.TargetEncoder(cols=self.cols, drop_invariant=self.drop_invariant, return_df=self.return_df)\n\n    def fit(self, X, y=None):\n        self.encoder.fit(X, y)\n        return self\n\n    def transform(self, X, y=None):\n        return self.encoder.transform(X, y)    \n    \n\nclass SimpleImputerWrapper(BaseEstimator, TransformerMixin):\n    def __init__(self, strategy='mean'):\n        self.strategy = strategy\n        self.imputer = SimpleImputer(strategy=strategy)\n    \n    def fit(self, X, y=None):\n        self.imputer.fit(X)\n        return self\n    \n    def transform(self, X):\n        X_transformed = self.imputer.transform(X)\n        return pd.DataFrame(X_transformed, columns=X.columns, index=X.index)\n    \n    \nclass PercentageVariationTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, variable):\n        self.variable = variable\n\n    def fit(self, X, y):\n        # Combine X and y for easier calculations\n        data = pd.concat([X, y], axis=1)\n\n        # Calculate the mean of the variable for different target values\n        self.target_means = data.groupby(y.name)[self.variable].mean()\n        return self\n\n    def transform(self, X, y=None):\n        result = pd.DataFrame()\n\n        # Calculate the percentage variation for each target mean\n        for target_value, target_mean in self.target_means.items():\n            column_name = f\"{self.variable}_pct_variation_{target_value}\"\n            result[column_name] = (X[self.variable] - target_mean) / target_mean * 100\n\n        return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## feature engineering","metadata":{}},{"cell_type":"code","source":"class RatioFeature(BaseEstimator, TransformerMixin):\n    def __init__(self, base_var, other_vars):\n        self.base_var = base_var\n        self.other_vars = other_vars if other_vars is not None else []\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        # Asegurarse de que el input es un DataFrame de pandas\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"El input debe ser un DataFrame de pandas\")\n\n        # Verificar que base_var existe en el DataFrame\n        if self.base_var not in X.columns:\n            raise ValueError(f\"La columna '{self.base_var}' no se encuentra en el DataFrame\")\n\n        # Crear un DataFrame vacío para almacenar las nuevas features\n        new_features = pd.DataFrame()\n\n        # Calcular las nuevas features\n        for var in self.other_vars:\n            if var in X.columns:\n                feature_name = f\"{self.base_var}_{var}_ratio\"\n                new_features[feature_name] = X[self.base_var] / X[var]\n            else:\n                raise ValueError(f\"La columna '{var}' no se encuentra en el DataFrame\")\n        return new_features\n    \n    \nclass JoinColumnsTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, like_strings):\n        self.like_strings = like_strings\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        # Asegurarse de que el input es un DataFrame de pandas\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"El input debe ser un DataFrame de pandas\")\n\n        # Crear un DataFrame vacío para almacenar las nuevas columnas\n        new_cols = pd.DataFrame(index=X.index)\n\n        # Iterar sobre las cadenas especificadas\n        for like_string in self.like_strings:\n            # Filtrar las columnas que contienen la cadena específica\n            joined_cols = X.filter(like=like_string)\n\n            # Crear una nueva columna con la suma de las columnas filtradas\n            new_col_name = 'sum_'+like_string\n            new_cols[new_col_name] = joined_cols.sum(axis=1)\n        return new_cols\n    \n\n\nclass StandardScalerTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, columns=None):\n        self.columns = columns\n        self.scaler = StandardScaler()\n        \n    def fit(self, X, y=None):\n        cols_to_scale = X.select_dtypes(include='number').columns if self.columns is None else self.columns\n        self.scaler.fit(X[cols_to_scale])\n        return self\n        \n    def transform(self, X):\n        cols_to_scale = X.select_dtypes(include='number').columns if self.columns is None else self.columns\n        X_transformed = pd.DataFrame(self.scaler.transform(X[cols_to_scale]), columns=cols_to_scale, index=X.index)\n        return pd.concat([X.drop(columns=cols_to_scale), X_transformed], axis=1)    \n    \n\n\nclass ReplaceInfTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, factor = 3):\n        self.column_max_values = {}\n        self.column_min_values = {}\n        self.factor = factor\n\n    def fit(self, X, y=None):\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"Input should be a pandas DataFrame\")\n\n        for column in X.columns:\n            max_value = X[column].replace([np.inf, -np.inf], np.nan).max()\n            min_value = X[column].replace([np.inf, -np.inf], np.nan).min()\n\n            self.column_max_values[column] = max_value\n            self.column_min_values[column] = min_value\n\n        return self\n\n    def transform(self, X, y=None):\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"Input should be a pandas DataFrame\")\n\n        X_copy = X.copy()\n\n        for column in X_copy.columns:\n            if column in self.column_max_values:\n                X_copy[column] = X_copy[column].replace(np.inf, self.column_max_values[column] * self.factor)\n            if column in self.column_min_values:\n                X_copy[column] = X_copy[column].replace(-np.inf, self.column_min_values[column] * self.factor)\n\n        return X_copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binning = Pipeline([\n    ('col_select',ColumnSelector(columns=cols_to_binarize)),\n    ('bin_convert',BinTransformer(columns=None, n_bins = 3)),\n    ('onehot', OneHotEncoderTransformer())\n    #('target_encoding', TargetEncoderWrapper()) \n])\n\nstandarize = Pipeline([\n    ('col_select',ColumnSelector(columns=cols_to_normalize)),\n    ('scale', StandardScalerTransformer(columns=cols_to_normalize)),\n])\n\nfeature_engineering = PandasFeatureUnion([\n    ('as_is', ColumnSelector(columns=cols_keep_as_is)),\n    ('log', standarize),\n    ('bin_convert',binning)\n])\n\npreprocessing = Pipeline([    \n    ('inf', ReplaceInfTransformer()),\n    #('fillna', SimpleImputerWrapper(strategy='mean')),\n    ('feature_engineering', feature_engineering)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dataset.drop('clase_ternaria', axis=1)\ny = dataset['clase_ternaria']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n\n# Fit the preprocessing pipeline on the training set and transform both the training and test sets\nX_train_processed = preprocessing.fit_transform(X_train, y_train)\nX_test_processed = preprocessing.transform(X_test)\n\n# Check the shapes of the processed data\nprint(X_train_processed.shape, X_test_processed.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model evaluation","metadata":{}},{"cell_type":"code","source":"def get_balanced_classes():\n    class_counts = y.value_counts()\n    total_samples = class_counts.sum()\n    class_frequencies = class_counts / total_samples\n    class_weights = 1 / class_frequencies\n    return class_weights.to_dict()\n\nclass_weights_dict = get_balanced_classes()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection._split import _BaseKFold\n\nclass WalkForwardCV(_BaseKFold):\n    def __init__(self, min_train_size, step):\n        n_splits = self._calculate_n_splits(min_train_size, step)\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.min_train_size = min_train_size\n        self.step = step\n\n    @staticmethod\n    def _calculate_n_splits(min_train_size, step):\n        return max((len(X_train_processed) - min_train_size) // step, 0)\n\n    def _iter_test_indices(self, X, y=None, groups=None):\n        n_samples = X.shape[0]\n        train_start = 0\n        while train_start + self.min_train_size < n_samples:\n            train_end = train_start + self.min_train_size\n            val_end = train_end + self.step\n            test_indices = np.arange(train_end, min(val_end, n_samples))\n            yield test_indices\n            train_start = train_end\n\n\nimport optuna\nimport lightgbm as lgb\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import KFold\nfrom lightgbm import early_stopping, log_evaluation\n\ndef objective(trial):\n    \n    #kf =  KFold(n_splits=3, shuffle=False)\n    \n    min_train_size = 25000\n    step = 6000\n    kf = WalkForwardCV(min_train_size=min_train_size, step=step)\n    \n    f1_scores = []\n    for train_index, val_index in kf.split(X_train_processed):\n        X_tr, X_val = X_train_processed.iloc[train_index], X_train_processed.iloc[val_index]\n        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n        \n        params = {\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True),\n            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 128),  # Fix the maximum value for num_leaves\n            \n            'class_weight': class_weights_dict,  \n            #\"objective\": \"multiclass\",\n            #\"metric\": \"multi_logloss\",\n            #\"num_class\": 3,\n            \"verbosity\": -1,\n            \"boosting_type\": \"gbdt\",   \n            'n_jobs': -1,\n#             \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),          \n            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 50),\n            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n#             \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n#             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n#             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n#             \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 1e-8, 1.0)\n        }\n\n        clf = lgb.LGBMClassifier(device='gpu', **params)\n        \n        try:\n            clf.fit(\n                X_tr, y_tr, \n                eval_set=[(X_val, y_val)], \n                callbacks=[early_stopping(50), lgb.log_evaluation(period=50)]\n            )    \n        \n        except lgb.basic.LightGBMError as e:\n            print(f\"Trial {trial.number} failed with parameters: {params}\")\n            if len(trial.study.trials) > 1:\n                print(f\"Current best parameters: {trial.study.best_params}\")\n            return -float('inf')  # Return very low score to skip this set of hyperparameters\n\n            \n        y_pred = clf.predict(X_val)\n        f1 = f1_score(y_val, y_pred, average='macro')\n        f1_scores.append(f1)\n\n    return sum(f1_scores) / len(f1_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def optimize_lgbm_hyperparameters():\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=100)\n\n    print(f\"Best trial: {study.best_trial.params}\")\n    print(f\"Best F1 score: {study.best_value}\")\n    return study.best_trial.params\n\nbest_params = optimize_lgbm_hyperparameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params =  {'learning_rate': 0.0379644295612985, 'max_depth': 8, 'num_leaves': 56, 'min_data_in_leaf': 14, 'feature_fraction': 0.46891355088542147}","metadata":{"execution":{"iopub.status.busy":"2023-05-02T03:09:46.980398Z","iopub.execute_input":"2023-05-02T03:09:46.980868Z","iopub.status.idle":"2023-05-02T03:09:46.987011Z","shell.execute_reply.started":"2023-05-02T03:09:46.980826Z","shell.execute_reply":"2023-05-02T03:09:46.985662Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"import shap\nfrom lightgbm import LGBMClassifier\n\n#class_weight = {0:1, 1:40}\n\nmodel = LGBMClassifier(device='gpu',class_weight = class_weights_dict, **best_params)\n\nmodel.fit(X_train_processed, y_train)\n\ny_pred_proba = model.predict_proba(X_test_processed)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T03:09:47.369120Z","iopub.execute_input":"2023-05-02T03:09:47.370284Z","iopub.status.idle":"2023-05-02T03:10:06.149279Z","shell.execute_reply.started":"2023-05-02T03:09:47.370243Z","shell.execute_reply":"2023-05-02T03:10:06.148138Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n[LightGBM] [Warning] feature_fraction is set=0.46891355088542147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46891355088542147\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score\nfrom sklearn.model_selection import KFold, train_test_split\n\n# Define the KFold cross-validator\n# n_splits = 5\n# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nmin_train_size = 25000\nstep = 6000\nkf = WalkForwardCV(min_train_size=min_train_size, step=step)\n\n# Split the dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n\n# Initialize the F1 scores list\nf1_scores = []\n\n# Perform cross-validation\nfor train_index, val_index in kf.split(X_train, y_train):\n    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n    \n    # Fit the preprocessing pipeline on the training set and transform both the training and validation sets\n    X_tr_processed = preprocessing.fit_transform(X_tr, y_tr)\n    X_val_processed = preprocessing.transform(X_val)\n\n    # Train the model\n    model.fit(X_tr_processed, y_tr)\n    \n    # Make predictions\n    y_pred = model.predict(X_val_processed)\n    \n    # Calculate the F1 score\n    f1 = f1_score(y_val, y_pred, average='macro')\n    f1_scores.append(f1)\n    \n    # Print the F1 score for the current fold\n    print(f\"F1 score for fold {len(f1_scores)}: {f1:.4f}\")\n\n# Calculate and print the average F1 score\naverage_f1 = np.mean(f1_scores)\nprint(f\"Average F1 score: {average_f1:.4f}\")\n\n# Fit the preprocessing pipeline on the entire training set and transform both the training and test sets\nX_train_processed = preprocessing.fit_transform(X_train, y_train)\nX_test_processed = preprocessing.transform(X_test)\n\n# Train the model on the entire training set\nmodel.fit(X_train_processed, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test_processed)\n\n# Plot the confusion matrix for the test set\ncm = confusion_matrix(y_test, y_pred)\nax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nplt.show()\n\n# Print the classification report for the test set\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T03:18:33.132107Z","iopub.execute_input":"2023-05-02T03:18:33.133137Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"F1 score for fold 1: 0.4715\n[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n[LightGBM] [Warning] feature_fraction is set=0.46891355088542147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46891355088542147\nF1 score for fold 2: 0.3981\nAverage F1 score: 0.4348\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test_processed)\n\ncm = confusion_matrix(y_test, y_pred)\nax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nplt.show()\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-05-02T03:10:07.213661Z","iopub.execute_input":"2023-05-02T03:10:07.214053Z","iopub.status.idle":"2023-05-02T03:10:08.253699Z","shell.execute_reply.started":"2023-05-02T03:10:07.214016Z","shell.execute_reply":"2023-05-02T03:10:08.252253Z"},"trusted":true},"execution_count":215,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.72      0.84     26061\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.72     26061\n   macro avg       0.50      0.36      0.42     26061\nweighted avg       1.00      0.72      0.84     26061\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# prediccion","metadata":{}},{"cell_type":"code","source":"# Read the dataset\npredict_set = pd.read_csv('/kaggle/input/dset-peq/dataset_pequeno.csv')\n\ndapply = predict_set[predict_set['foto_mes'] == 202109].drop('clase_ternaria', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:28:02.981632Z","iopub.execute_input":"2023-05-02T02:28:02.982358Z","iopub.status.idle":"2023-05-02T02:28:07.300995Z","shell.execute_reply.started":"2023-05-02T02:28:02.982305Z","shell.execute_reply":"2023-05-02T02:28:07.299857Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"dapply = preprocessing_dataset(dapply,palabras_agrupar)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:28:08.309563Z","iopub.execute_input":"2023-05-02T02:28:08.310593Z","iopub.status.idle":"2023-05-02T02:28:09.954684Z","shell.execute_reply.started":"2023-05-02T02:28:08.310508Z","shell.execute_reply":"2023-05-02T02:28:09.953340Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"(165237, 154)\ndropeando ['Master_Finiciomora', 'Visa_Finiciomora'] porque tienen mas de 0.8 Nan...\n(165237, 152)\njuntando columnas con prefijo Visa_ y Master_\n(165237, 131)\nsumando las columnas: ['cprestamos_personales', 'mprestamos_personales', 'cprestamos_prendarios', 'mprestamos_prendarios', 'cprestamos_hipotecarios', 'mprestamos_hipotecarios']...\n(165237, 126)\nsumando las columnas: ['cseguro_vida', 'cseguro_auto', 'cseguro_vivienda', 'cseguro_accidentes_personales']...\n(165237, 123)\nsumando las columnas: ['cpagodeservicios', 'mpagodeservicios']...\n(165237, 122)\nsumando las columnas: ['mcomisiones', 'ccomisiones_mantenimiento', 'mcomisiones_mantenimiento', 'ccomisiones_otras', 'mcomisiones_otras']...\n(165237, 118)\nsumando las columnas: ['ccheques_depositados', 'mcheques_depositados', 'ccheques_emitidos', 'mcheques_emitidos', 'ccheques_depositados_rechazados', 'mcheques_depositados_rechazados', 'ccheques_emitidos_rechazados', 'mcheques_emitidos_rechazados']...\n(165237, 111)\nsumando las columnas: ['ccaja_ahorro', 'mcaja_ahorro', 'mcaja_ahorro_adicional', 'mcaja_ahorro_dolares']...\n(165237, 108)\nsumando las columnas: ['cinversion1', 'minversion1_pesos', 'minversion1_dolares', 'cinversion2', 'minversion2']...\n(165237, 104)\nsumando las columnas: ['mtarjeta_visa_consumo', 'mtarjeta_master_consumo']...\n(165237, 103)\nsumando las columnas: ['ccajeros_propios_descuentos', 'mcajeros_propios_descuentos', 'ctarjeta_visa_descuentos', 'mtarjeta_visa_descuentos', 'ctarjeta_master_descuentos', 'mtarjeta_master_descuentos']...\n(165237, 98)\nsumando las columnas: ['ctarjeta_debito', 'ctarjeta_debito_transacciones', 'ctarjeta_visa', 'ctarjeta_visa_transacciones', 'ctarjeta_master', 'ctarjeta_master_transacciones', 'ctarjeta_visa_debitos_automaticos', 'mttarjeta_visa_debitos_automaticos', 'ctarjeta_master_debitos_automaticos', 'mttarjeta_master_debitos_automaticos']...\n(165237, 89)\nsumando las columnas: ['sum_mconsumospesos', 'sum_mconsumosdolares', 'sum_mconsumototal', 'sum_cconsumos', '_consumo']...\n(165237, 85)\nsumando las columnas: ['mactivos_margen', 'mpasivos_margen']...\n(165237, 84)\nsumando las columnas: ['ccuenta_debitos_automaticos', 'mcuenta_debitos_automaticos']...\n(165237, 83)\nsumando las columnas: ['cforex', 'cforex_buy', 'mforex_buy', 'cforex_sell', 'mforex_sell']...\n(165237, 79)\nsumando las columnas: ['ctransferencias_recibidas', 'mtransferencias_recibidas', 'ctransferencias_emitidas', 'mtransferencias_emitidas']...\n(165237, 76)\nsumando las columnas: ['mautoservicio', 'cextraccion_autoservicio', 'mextraccion_autoservicio']...\n(165237, 74)\nsumando las columnas: ['ccajas_transacciones', 'ccajas_consultas', 'ccajas_depositos', 'ccajas_extracciones', 'ccajas_otras']...\n(165237, 70)\nsumando las columnas: ['catm_trx', 'matm', 'catm_trx_other', 'matm_other']...\n(165237, 67)\nsumando las columnas: ['tmobile_app', 'cmobile_app_trx']...\n(165237, 66)\n","output_type":"stream"}]},{"cell_type":"code","source":"dapply = create_ratios_from_best(dapply, list_of_best_ratios)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:28:11.380009Z","iopub.execute_input":"2023-05-02T02:28:11.380758Z","iopub.status.idle":"2023-05-02T02:28:11.995034Z","shell.execute_reply.started":"2023-05-02T02:28:11.380714Z","shell.execute_reply":"2023-05-02T02:28:11.993862Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"Skipping invalid ratio: error with sum_delinquency\nSkipping invalid ratio: error with sum_status\nSkipping invalid ratio: error with sum_madelantopesos\nSkipping invalid ratio: error with sum_madelantodolares\nSkipping invalid ratio: error with sum_mpagosdolares\nSkipping invalid ratio: error with sum_cadelantosefectivo\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_result = model.predict_proba(preprocessing.transform(dapply))\n\n# Create a DataFrame for predicted labels using the same index as numero_de_cliente\npredicted_df = pd.DataFrame(y_pred_result[:, 1], columns=['proba'], index=dapply.index)\n\n# Combine the numero_de_cliente and predicted labels\nend_res = pd.concat([dapply['numero_de_cliente'], predicted_df], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:42:35.881934Z","iopub.execute_input":"2023-05-02T02:42:35.882477Z","iopub.status.idle":"2023-05-02T02:42:44.593283Z","shell.execute_reply.started":"2023-05-02T02:42:35.882429Z","shell.execute_reply":"2023-05-02T02:42:44.592197Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"def get_nth(end_res, n):\n    get_nth = end_res.sort_values('proba', ascending=False).head(n).iloc[-1]['proba']\n    end_res['Predicted'] = (end_res['proba'] >= get_nth).astype(int)\n    end_res.drop(columns='proba', inplace=True)\n    return end_res","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:42:45.499182Z","iopub.execute_input":"2023-05-02T02:42:45.499564Z","iopub.status.idle":"2023-05-02T02:42:45.505847Z","shell.execute_reply.started":"2023-05-02T02:42:45.499529Z","shell.execute_reply":"2023-05-02T02:42:45.504655Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"end_result = get_nth(end_res,n=8500)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:42:45.934588Z","iopub.execute_input":"2023-05-02T02:42:45.935260Z","iopub.status.idle":"2023-05-02T02:42:45.970070Z","shell.execute_reply.started":"2023-05-02T02:42:45.935219Z","shell.execute_reply":"2023-05-02T02:42:45.968845Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"end_result['Predicted'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:42:46.825361Z","iopub.execute_input":"2023-05-02T02:42:46.825813Z","iopub.status.idle":"2023-05-02T02:42:46.837111Z","shell.execute_reply.started":"2023-05-02T02:42:46.825772Z","shell.execute_reply":"2023-05-02T02:42:46.835801Z"},"trusted":true},"execution_count":183,"outputs":[{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"0    156737\n1      8500\nName: Predicted, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"end_result.to_csv(\"K101_001.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:42:48.213227Z","iopub.execute_input":"2023-05-02T02:42:48.214328Z","iopub.status.idle":"2023-05-02T02:42:48.367137Z","shell.execute_reply.started":"2023-05-02T02:42:48.214275Z","shell.execute_reply":"2023-05-02T02:42:48.365875Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['KAGGLE_USERNAME'] = 'lechuck666'\nos.environ['KAGGLE_KEY'] = '3aaf0a00c8b35504b64d43d4592d6caf'\n!kaggle competitions submit -c laboratorio-de-imp-i-2023-virtual -f ./K101_001.csv -m \"2nd_less var\"","metadata":{"execution":{"iopub.status.busy":"2023-05-02T02:42:48.440859Z","iopub.execute_input":"2023-05-02T02:42:48.441514Z","iopub.status.idle":"2023-05-02T02:42:51.313854Z","shell.execute_reply.started":"2023-05-02T02:42:48.441467Z","shell.execute_reply":"2023-05-02T02:42:51.312544Z"},"trusted":true},"execution_count":185,"outputs":[{"name":"stdout","text":"100%|██████████████████████████████████████| 1.81M/1.81M [00:00<00:00, 8.33MB/s]\nSuccessfully submitted to Laboratorio de Imp I, 2023 virtual","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}